{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education.num   32561 non-null  int64 \n",
      " 5   marital.status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital.gain    32561 non-null  int64 \n",
      " 11  capital.loss    32561 non-null  int64 \n",
      " 12  hours.per.week  32561 non-null  int64 \n",
      " 13  native.country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data Loading\n",
    "dataset = pd.read_csv('adult.csv')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 7)\n",
      "(32561,)\n"
     ]
    }
   ],
   "source": [
    "# Data Pre-processing\n",
    "dataset = dataset.fillna(np.nan)\n",
    "# Drop the data I don't want to use\n",
    "dataset.drop(labels=[\"workclass\",\"fnlwgt\", \"education\",\"occupation\",\"relationship\",\"race\",\"native.country\"], axis = 1, inplace = True)\n",
    "# Reformat Column We Are Predicting: 0 means less than 50K. 1 means greater than 50K.\n",
    "dataset['income']=dataset['income'].map({'<=50K': 0, '>50K': 1, '<=50K.': 0, '>50K.': 1})\n",
    "# Convert Sex value to 0 and 1\n",
    "dataset[\"sex\"] = dataset[\"sex\"].map({\"Male\": 0, \"Female\":1})\n",
    "# Create Married Column - Binary Yes(1) or No(0)\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].replace(['Never-married','Divorced','Separated','Widowed'], 'Single')\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].replace(['Married-civ-spouse','Married-spouse-absent','Married-AF-spouse'], 'Married')\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].map({\"Married\":1, \"Single\":0})\n",
    "dataset[\"marital.status\"] = dataset[\"marital.status\"].astype(int)\n",
    "array = dataset.values\n",
    "X = array[:,0:7]\n",
    "Y = array[:,7]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22792, 7)\n",
      "(22792,)\n",
      "(9769, 7)\n",
      "(9769,)\n"
     ]
    }
   ],
   "source": [
    "# Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,Y,train_size=0.7,random_state=2021,stratify=Y)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction class\n",
      "[0]\n",
      "prediciton probability\n",
      "[[0.75335648 0.24664352]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\79192\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "# D1F\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=2021).fit(train_x,train_y)\n",
    "print('prediction class')\n",
    "print(lr.predict([test_x[2021]]))\n",
    "print('prediciton probability')\n",
    "print(lr.predict_proba([test_x[2021]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is  0.8216479466479466\n",
      "The test accuracy is  0.8199406285187839\n"
     ]
    }
   ],
   "source": [
    "# D2F\n",
    "print(\"The training accuracy is \", lr.score(train_x, train_y))\n",
    "print(\"The test accuracy is \", lr.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision on train set is  0.7348284960422163\n",
      "The recall on train set is  0.40590271451994897\n",
      "The f1 score on train set is  0.5229433165121464\n",
      "The precision on test set is  0.7329143754909663\n",
      "The recall on test set is  0.39668367346938777\n",
      "The f1 score on test set is  0.5147586206896552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "train_pred = lr.predict(train_x)\n",
    "print(\"The precision on train set is \", precision_score(train_y, train_pred))\n",
    "print(\"The recall on train set is \", recall_score(train_y, train_pred))\n",
    "print(\"The f1 score on train set is \", f1_score(train_y, train_pred))\n",
    "test_pred = lr.predict(test_x)\n",
    "print(\"The precision on test set is \", precision_score(test_y, test_pred))\n",
    "print(\"The recall on test set is \", recall_score(test_y, test_pred))\n",
    "print(\"The f1 score on test set is \", f1_score(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction class\n",
      "[0]\n",
      "prediciton probability\n",
      "[[0.81288558 0.18711442]]\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "# D1F\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=2021,probability=True).fit(train_x,train_y)\n",
    "print('prediction class')\n",
    "print(svm.predict([test_x[2021]]))\n",
    "print('prediciton probability')\n",
    "print(svm.predict_proba([test_x[2021]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is  0.8016409266409267\n",
      "The test accuracy is  0.8039717473641109\n"
     ]
    }
   ],
   "source": [
    "# D2F\n",
    "print(\"The training accuracy is \", svm.score(train_x, train_y))\n",
    "print(\"The test accuracy is \", svm.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision on train set is  0.7333654773384763\n",
      "The recall on train set is  0.2770996538531609\n",
      "The f1 score on train set is  0.40222134073780247\n",
      "The precision on test set is  0.7567567567567568\n",
      "The recall on test set is  0.27380952380952384\n",
      "The f1 score on test set is  0.40212300967842646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "train_pred = svm.predict(train_x)\n",
    "print(\"The precision on train set is \", precision_score(train_y, train_pred))\n",
    "print(\"The recall on train set is \", recall_score(train_y, train_pred))\n",
    "print(\"The f1 score on train set is \", f1_score(train_y, train_pred))\n",
    "test_pred = svm.predict(test_x)\n",
    "print(\"The precision on test set is \", precision_score(test_y, test_pred))\n",
    "print(\"The recall on test set is \", recall_score(test_y, test_pred))\n",
    "print(\"The f1 score on test set is \", f1_score(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3iaml",
   "language": "python",
   "name": "py3iaml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
